{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-arm Bandits\n",
    "## Feedback\n",
    "**Evaluative Feedback**: \n",
    "- In it's pure form, depends only on the action taken\n",
    "- Tells us how good was the action we took\n",
    "- Doesn't tell us which action was best\n",
    "\n",
    "**Instructive Feedback**:  \n",
    "- In it's pure form, independent of the action taken\n",
    "- Tells us which action was best to take\n",
    "- Doesn't indicate how well our action (or any other for that matter) performed\n",
    "- Used in its pure form for Supervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-armed Bandit\n",
    "\n",
    "Faced with a choice of K different options / actions.  After each action, you receive an immidiate numerical reward (depends on the action).  \n",
    "The objective is to Maximize the total reward over N time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A_t$: Action selected at time $t$  \n",
    "$R_t$: Reward for $A_t$  \n",
    "$\\large{q_*(a)}$: $\\large{\\mathbb{E}[R_t|A_t=a]}$    //The expected value of reward, given action $a$ is selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the problem?    We can just always choose the highest expected reward action!  \n",
    "This is true! When we know $q*(a)$ we can be *greedy* and **exploit** this information and choose the most valueable action.  \n",
    "BUT, In most situations we will not know what is $q*(a)$.  \n",
    "Because we don't know what $q*(a)$ is, we will need to **explore** and increase our certainty about $q*(a)$ for different actions.  (Make $Q_t(a)$ as close to $q*(a)$ as possible)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action-Value Methods\n",
    "This methods are used to evalate the true *value* of an action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: *Sample Average*\n",
    "The Value of an action is the mean reward from doing that action up to current time.  \n",
    "We can easily formulate it to:\n",
    "$\\Large{Q_t(a) = \\frac{\\sum_{i=1}^{t-1}{R_i * \\mathbb{1}_{A_i=a}}}{\\sum_{i=1}^{t-1}{\\mathbb{1}_{A_i=a}}}}$  \n",
    "$\\mathbb{1}_{predicate}$ = 1 if true, else 0  \n",
    "\n",
    "In this equation, $\\sum_{i=1}^{t-1}{\\mathbb{1}_{A_i=a}} \\rightarrow \\infty$, $Q_t(a)$ $\\rightarrow$ $q*(a)$  \n",
    "\n",
    "We can couple this equation, with the selection method: $A_t=\\underset{a}{\\arg\\max} {Q_t(a)}$ for a *greedy* selection process\n",
    "\n",
    "#### $\\large\\epsilon-{greedy}$ Selection Method\n",
    "Since we want to support **exploration** factor e for ~ $\\epsilon$ of the times, we can set a rule so that:  \n",
    "$A_t(e)= \\{ \\array{\\underset{a}{\\arg\\max} {Q_t(a)} & for & 1 \\geq e \\gt \\epsilon \\\\ Random(a) & for & \\epsilon \\geq e \\geq 0 } \\}$  \n",
    "\n",
    "In this case, we know that we **Explore** for $\\epsilon$ of the time, and **Exploit** for $1-\\epsilon$ of the time  \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1**: In \"$\\epsilon$-greedy action selection, for the case of two actions and $\\epsilon$ = 0.5, what is the probability that the greedy action is selected?  \n",
    "\n",
    "**Answer**: The greedy action is selected $1-\\epsilon$ of the times, so:  \n",
    "$\\epsilon=0.5 \\| 1-\\epsilon=0.5 \\\\ {Or} \\\\ $  \n",
    "$\\Pr(e|e\\geq0.5) = 0.5 = 50\\%$  \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
